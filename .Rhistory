npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model, preProcess="scale", trControl=control)
models <- list(models, list1)
}
return(models)
}
models <- train_with_different_features("svmLinear2", 0.75)
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
train_with_different_features <- function(model, corr_cutoff){Â´
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model, preProcess="scale", trControl=control)
models <- list(model1)
for(i in 2:2){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model, preProcess="scale", trControl=control)
models <- list(models, list1)
}
return(models)
}
print(get_non_correlated_features("npf_train.csv", 0.75))
models <- train_with_different_features("svmLinear2", 0.75)
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model, preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method="svmLinear2", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
train_with_different_features("svmLinear2", 0.75)
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
models <- list()
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
models <- list()
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
models <- list(models, model1)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
return(models)
}
models <- train_with_different_features("svmLinear2", 0.75)
print(models)
print(models[1])
print(models[2])
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
models <- list()
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
models <- list(models, model1)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
return(models[,-1])
}
models <- train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
models <- list()
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
models <- list(models, model1)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
return(models[-1])
}
models <- train_with_different_features("svmLinear2", 0.75)
models <- train_with_different_features("svmLinear2", 0.75)
print(models[1])
for(model in models){
print(model)
}
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
accuracy[i] <- sapply(models[i]$result, mean)[2]
}
plot(accuracy)
}
models <- train_with_different_features("svmLinear2", 0.75)
models <- train_with_different_features("svmLinear2", 0.75)
plot_accuracies(models)
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
accuracy[i] <- sapply(models[i]$result, mean)[2]
}
print(accuracy)
plot(accuracy)
}
plot_accuracies(models)
print(models)
sapply(models[i]$result, mean)[2]
sapply(models[1]$result, mean)[2]
models[1]$result
print(models)
print(models[1])
models[1]$result
print(models[1])
print(models[1][1])
models[1]$result
print(models[1][1])
print(models[1][1][1])
print(models[1][1][1])
print(models)
models <- train_with_different_features("svmLinear2", 0.75)
models <- train_with_different_features("svmLinear2", 0.75)
print(models)
models[1]$result
print(models)
print(models[2])
print(models[1])
print(models[1]$result)
print(models[[1]]$result)
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
accuracy[i] <- sapply(models[i]$result, mean)[[2]]
}
print(accuracy)
plot(accuracy)
}
models <- train_with_different_features("svmLinear2", 0.75)
plot_accuracies(models)
print(length(models))
plot_accuracies(models)
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
accuracy[i] <- sapply(models[i]$result, mean)[[i]]
}
print(accuracy)
plot(accuracy)
}
plot_accuracies(models)
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
print(i)
accuracy[i] <- sapply(models[i]$result, mean)[[i]]
}
print(accuracy)
plot(accuracy)
}
plot_accuracies(models)
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
print(i)
accuracy[i] <- sapply(models[[i]]$result, mean)[2]
}
print(accuracy)
plot(accuracy)
}
plot_accuracies(models)
train_with_different_cutoff <- function(model_name, cutoffs){
models <- list()
for(cutoff in cutoffs){
models <- list(models, train_with_different_features(model_name, cutoff))
}
return models
train_with_different_cutoff <- function(model_name, cutoffs){
models <- list()
for(cutoff in cutoffs){
models <- list(models, train_with_different_features(model_name, cutoff))
}
return(models)
}
models <- train_with_different_features("svmLinear2", c(0.75))
plot_accuracies(models)
print(models[[1]]$result)
print(sapply(models[[1]]$result, mean))
print(models[[1]]$result)
models <- train_with_different_features("rf", c(0.75))
print(models[[1]]$result)
models <- train_with_different_features("svmLinear2", c(0.75))
models <- train_with_different_features("svmLinear2", c(0.75))
print(models[[1]]$result)
plot(model)
plot(models[[1]])
print(models[[1]]$result)
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=5,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
models <- list()
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
models <- list(models, model1)
}
return(models[-1])
}
plot_accuracies <- function(models){
n <- length(models)
accuracy <- rep(0,n)
for(i in 1:n){
print(i)
accuracy[i] <- sapply(models[[i]]$result, mean)[2]
}
print(accuracy)
plot(accuracy)
}
train_with_different_cutoff <- function(model_name, cutoffs){
models <- list()
for(cutoff in cutoffs){
models <- list(models, train_with_different_features(model_name, cutoff))
}
return(models)
}
models <- train_with_different_features("svmLinear2", c(0.75))
models <- train_with_different_features("svmLinear2", c(0.75))
print(models[[1]]$result)
train_with_different_features <- function(model_name, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=5,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
models <- list()
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method=model_name, preProcess="scale", trControl=control)
models <- list(models, model1)
}
return(models[-1])
}
models <- train_with_different_features("svmLinear2", c(0.75))
models <- train_with_different_features("svmLinear2", c(0.75))
print(models[[1]]$result)
knitr::opts_chunk$set(echo = TRUE)
npf <-read.csv("npf_train.csv")
print(npf)
print("Hello")
save_binary_importance_csv("nb")
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
get_full_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
cm <- cor(npf[,-1]) # note that we ignore the class column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
get_importance <- function(model){
print("Here")
print(model)
plot(varImp(model, scale=FALSE), ylab="Variables")
print("Here2")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
print(importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
return(importance)
}
plot_importance <- function(model_name){
npf <- get_non_correlated_features("npf_train.csv", 0.75)
control <- trainControl(method="repeatedcv", number=10, repeats=5,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
}
save_binary_importance_csv <- function(model_name){
npf <- get_non_correlated_features("npf_train.csv", 0.75)
control <- trainControl(method="repeatedcv", number=10, repeats=5,classProbs=TRUE)
model <- train(class2~., data=npf, method=model_name, preProcess="scale", trControl=control)
importance <- get_importance(model)
s = "${model}_binary.csv"
csv_name = stringr::str_interp(s, list(model=model_name))
write.csv(importance, csv_name)
}
save_binary_importance_csv("nb")
