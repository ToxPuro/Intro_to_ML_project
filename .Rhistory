print("NULL")
}
print(importance)
print(importance)
if (is.null(importance$event)){
print("NULL")
}
npf <- get_non_correlated_features("npf_train.csv", 0.75)
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
print(importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
npf70names <- sap
importance <- importance[order(feature_importance,decreasing = T),]
print(importance)
print(feature_importance)
importance <- importance[order(feature_importance,decreasing = T),]
print(importance)
npf <- read.csv("npf_train.csv") #read in data
npf_test <- read.csv("npf_test_hidden.csv")
npf_test
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf_test <- npf_test[,-c(1:2,4)]
print(npf)
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- read.csv("npf_train.csv") #read in data
npf_test <- read.csv("npf_test_hidden.csv")
npf_test
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf_test <- npf_test[,-c(1:2,4)]
print(npf)
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
set.seed(7)
# lets use caret
library(caret)
#note that classprobs argument has to be true if we want svm to give probabilities
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="svmLinear2", preProcess="scale", trControl=control)
#lets sort the importances
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
importance <- importance[order(importance$event,decreasing = T),]
plot(model)
plot(varImp(model, scale=FALSE), ylab="Variables")
print(importance)
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))] #move class2 column to first
npf75names <- sapply(importance[importance["event"]>0.75,]$names, function(x) toString(x)) #33 features
npf82names <- sapply(importance[importance["event"]>0.80,]$names, function(x) toString(x))# 12
npf83_8names <- sapply(importance[importance["event"]>0.838,]$names, function(x) toString(x))#6
npf75 <- npf[, c("class2",npf75names)]
npf82 <- npf[, c("class2",npf82names)]
npf83_8 <- npf[, c("class2",npf83_8names)]
model1 <- train(class2~., data=npf75, method="svmLinear2", preProcess="scale", trControl=control)
model2 <- train(class2~., data=npf82, method="svmLinear2", preProcess="scale", trControl=control)
model3 <- train(class2~., data=npf83_8, method="svmLinear2", preProcess="scale", trControl=control)
library(knitr)
df <- setNames(data.frame(matrix(ncol = 4, nrow = 3)), names(model1$results)[2:5])
rownames(df) <- c("npf75", "npf82", "npf83_8")
df[1,] = sapply(model1$results, mean)[2:5] #mean is over the 3 repetitions of the 10 fold cv.
df[2,] = sapply(model2$results, mean)[2:5]
df[3,] = sapply(model3$results, mean)[2:5]
kable(df)
library(GGally)
ggpairs(npf83_8, aes(colour = class2, alpha = 0.4))
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = 0.75)+1 #+1 to get the indexing in the npf df where class2 bumps all the indices up by 1.
print(highcorr) # indices of what we want to cut
npf <- npf[,-c(highcorr)]
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="svmLinear2", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
#lets sort the importances
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
importance <- importance[order(importance$event,decreasing = T),]
npf70names <- sapply(importance[importance["event"]>0.70,]$names, function(x) toString(x)) #6 features
npf75names <- sapply(importance[importance["event"]>0.75,]$names, function(x) toString(x)) # 4 features
npf70 <- npf[, c("class2",npf70names)]
npf75 <- npf[, c("class2",npf75names)]
ggpairs(npf70, aes(colour = class2, alpha = 0.4))
model1 <- train(class2~., data=npf70, method="svmLinear2", preProcess="scale", trControl=control)
model2 <- train(class2~., data=npf75, method="svmLinear2", preProcess="scale", trControl=control)
df <- setNames(data.frame(matrix(ncol = 4, nrow = 2)), names(model1$results)[2:5])
rownames(df) <- c("npf70", "npf75")
df[1,] = sapply(model1$results, mean)[2:5] #mean is over the 3 repetitions of the 10 fold cv.
df[2,] = sapply(model2$results, mean)[2:5]
kable(df)
#lets sort the importances
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
print(importance$event)
importance <- importance[order(importance$event,decreasing = T),]
print(importance)
npf <- get_non_correlated_features("npf_train.csv", 0.75)
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
print(importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
print(feature_importance)
importance <- importance[order(feature_importance,decreasing = T),]
print(importance)
npf70names <- sapply(importance$names[1:2], function(x) toString(x)) #6 features
npf70names
npf <- get_non_correlated_features("npf_train.csv", 0.75)
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
print(importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
print(feature_importance)
importance <- importance[order(feature_importance,decreasing = T),]
npf70names <- sapply(importance$names[1:2], function(x) toString(x)) #6 features
npf1 <- npf[, c("class2",npf70names)]
model1 <- train(class2~., data=npf1, method=model, preProcess="scale", trControl=control)
model1 <- train(class2~., data=npf1, method="rf", preProcess="scale", trControl=control)
df <- setNames(data.frame(matrix(ncol = 4, nrow = 2)), names(model1$results)[2:5])
rownames(df) <- c("npf1", "npf2")
df[1,] = sapply(model1$results, mean)[2:5] #mean is over the 3 repetitions of the 10 fold cv.
kable(df)
print(importance)
kable(df)
npf <- get_non_correlated_features("npf_train.csv", 0.75)
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
print(importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
print(feature_importance)
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:25){
npf <- sapply(importance$names[1:i], function(x) toString(x))
model1 <- train(class2~., data=npf1, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2:5] #mean is over the 3 repetitions of the 10 fold cv.
}
plot(accuracy)
print(accuracy)
plot(accuracy, type="b")
npf <- get_non_correlated_features("npf_train.csv", 0.75)
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
model <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
print(importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
print(feature_importance)
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:25){
npf <- sapply(importance$names[1:i], function(x) toString(x))
model1 <- train(class2~., data=npf1, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:25){
npf <- sapply(importance$names[1:i], function(x) toString(x))
model1 <- train(class2~., data=npf1, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
train_with_most_important_features("svmLinear2", 0.75)
train_with_different_features("svmLinear2", 0.75)
npf <- read.csv("npf_train.csv") #read in data
npf_test <- read.csv("npf_test_hidden.csv")
npf_test
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf_test <- npf_test[,-c(1:2,4)]
print(npf)
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
set.seed(7)
# lets use caret
library(caret)
#note that classprobs argument has to be true if we want svm to give probabilities
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="svmLinear2", preProcess="scale", trControl=control)
#lets sort the importances
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
importance <- importance[order(importance$event,decreasing = T),]
plot(model)
plot(varImp(model, scale=FALSE), ylab="Variables")
print(importance)
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))] #move class2 column to first
npf75names <- sapply(importance[importance["event"]>0.75,]$names, function(x) toString(x)) #33 features
npf82names <- sapply(importance[importance["event"]>0.80,]$names, function(x) toString(x))# 12
npf83_8names <- sapply(importance[importance["event"]>0.838,]$names, function(x) toString(x))#6
npf75 <- npf[, c("class2",npf75names)]
npf82 <- npf[, c("class2",npf82names)]
npf83_8 <- npf[, c("class2",npf83_8names)]
model1 <- train(class2~., data=npf75, method="svmLinear2", preProcess="scale", trControl=control)
model2 <- train(class2~., data=npf82, method="svmLinear2", preProcess="scale", trControl=control)
model3 <- train(class2~., data=npf83_8, method="svmLinear2", preProcess="scale", trControl=control)
library(knitr)
df <- setNames(data.frame(matrix(ncol = 4, nrow = 3)), names(model1$results)[2:5])
rownames(df) <- c("npf75", "npf82", "npf83_8")
df[1,] = sapply(model1$results, mean)[2:5] #mean is over the 3 repetitions of the 10 fold cv.
df[2,] = sapply(model2$results, mean)[2:5]
df[3,] = sapply(model3$results, mean)[2:5]
kable(df)
library(GGally)
ggpairs(npf83_8, aes(colour = class2, alpha = 0.4))
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = 0.75)+1 #+1 to get the indexing in the npf df where class2 bumps all the indices up by 1.
print(highcorr) # indices of what we want to cut
npf <- npf[,-c(highcorr)]
print(npf)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method="svmLinear2", preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
#lets sort the importances
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
print(importance$event)
importance <- importance[order(importance$event,decreasing = T),]
print(importance)
npf70names <- sapply(importance[importance["event"]>0.70,]$names, function(x) toString(x)) #6 features
npf75names <- sapply(importance[importance["event"]>0.75,]$names, function(x) toString(x)) # 4 features
npf70 <- npf[, c("class2",npf70names)]
npf75 <- npf[, c("class2",npf75names)]
ggpairs(npf70, aes(colour = class2, alpha = 0.4))
model1 <- train(class2~., data=npf70, method="svmLinear2", preProcess="scale", trControl=control)
model2 <- train(class2~., data=npf75, method="svmLinear2", preProcess="scale", trControl=control)
df <- setNames(data.frame(matrix(ncol = 4, nrow = 2)), names(model1$results)[2:5])
rownames(df) <- c("npf70", "npf75")
df[1,] = sapply(model1$results, mean)[2:5] #mean is over the 3 repetitions of the 10 fold cv.
df[2,] = sapply(model2$results, mean)[2:5]
kable(df)
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
print(importance)
accuracy <- rep(0,25)
for(i in 1:25){
npf <- sapply(importance$names[1:i], function(x) toString(x))
model1 <- train(class2~., data=npf1, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
train_with_different_features("svmLinear2", 0.75)
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
print(importance)
accuracy <- rep(0,25)
for(i in 1:1){
npf <- sapply(importance$names[1:i], function(x) toString(x))
print(npf)
model1 <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:1){
npf <- sapply(importance$names[1:i], function(x) toString(x))
print(npf)
model1 <- train(class2~., data=npf, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:25){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
train_with_different_features("svmLinear2", 0.75)
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:5){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("svmLinear2", 0.75)
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:25){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("svmLinear2", 0.75)
library(caret)
get_non_correlated_features <- function(path, cutoff){
npf <- read.csv("npf_train.csv") #read in data
npf <- npf[,-c(1:2,4)] # drop the id, date, partlybad columns
npf$class2 <- factor("event",levels=c("nonevent", "event"))
npf$class2[npf$class4=="nonevent"] <- "nonevent"
npf <- npf[,-1]
npf <- npf[,c(ncol(npf),1:(ncol(npf)-1))]
cm <- cor(npf[,-1]) # note that we ignore the class 2 column here as we dont want to drop it obviously
# find attributes that are highly corrected (the threshold for being cut can be changed.)
highcorr <- findCorrelation(cm, cutoff = cutoff)+1
npf <- npf[,-c(highcorr)]
return(npf)
}
train_with_different_features <- function(model, corr_cutoff){
npf <- get_non_correlated_features("npf_train.csv", corr_cutoff)
control <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
model <- train(class2~., data=npf, method=model, preProcess="scale", trControl=control)
plot(varImp(model, scale=FALSE), ylab="Variables")
importance <- data.frame(varImp(model, scale=FALSE)$importance)
importance <- data.frame(importance, names = rownames(importance))
feature_importance <- importance$event
if (is.null(feature_importance)){
feature_importance <- importance$Overall
}
importance <- importance[order(feature_importance,decreasing = T),]
accuracy <- rep(0,25)
for(i in 1:1){
npfnames <- sapply(importance$names[1:i], function(x) toString(x))
npftrain <- npf[, c("class2",npfnames)]
model1 <- train(class2~., data=npftrain, method="rf", preProcess="scale", trControl=control)
accuracy[i] = sapply(model1$results, mean)[2] #mean is over the 3 repetitions of the 10 fold cv.
}
print(accuracy)
plot(accuracy, type="b")
}
print(get_non_correlated_features("npf_train.csv", 0.75))
train_with_different_features("regLogistic", 0.75)
