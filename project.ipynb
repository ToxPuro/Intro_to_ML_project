{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9a6f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a8ca92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>CO2168.mean</th>\n",
       "      <th>CO2168.std</th>\n",
       "      <th>CO2336.mean</th>\n",
       "      <th>CO2336.std</th>\n",
       "      <th>CO242.mean</th>\n",
       "      <th>CO242.std</th>\n",
       "      <th>CO2504.mean</th>\n",
       "      <th>CO2504.std</th>\n",
       "      <th>Glob.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>T672.mean</th>\n",
       "      <th>T672.std</th>\n",
       "      <th>T84.mean</th>\n",
       "      <th>T84.std</th>\n",
       "      <th>UV_A.mean</th>\n",
       "      <th>UV_A.std</th>\n",
       "      <th>UV_B.mean</th>\n",
       "      <th>UV_B.std</th>\n",
       "      <th>CS.mean</th>\n",
       "      <th>CS.std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>384.462000</td>\n",
       "      <td>2.284996</td>\n",
       "      <td>384.164462</td>\n",
       "      <td>2.135062</td>\n",
       "      <td>385.274688</td>\n",
       "      <td>2.211695</td>\n",
       "      <td>383.885077</td>\n",
       "      <td>1.955198</td>\n",
       "      <td>19.245511</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.016471</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>-12.422972</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>1.635563</td>\n",
       "      <td>0.856948</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>374.884615</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>374.703333</td>\n",
       "      <td>0.385179</td>\n",
       "      <td>375.621266</td>\n",
       "      <td>0.665720</td>\n",
       "      <td>374.674177</td>\n",
       "      <td>0.435480</td>\n",
       "      <td>31.107659</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.997430</td>\n",
       "      <td>0.373927</td>\n",
       "      <td>-8.351043</td>\n",
       "      <td>0.575679</td>\n",
       "      <td>1.441109</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>373.496585</td>\n",
       "      <td>0.189497</td>\n",
       "      <td>373.382593</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>373.961481</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>373.275062</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>29.800885</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.224472</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>-9.651155</td>\n",
       "      <td>1.238891</td>\n",
       "      <td>2.677545</td>\n",
       "      <td>1.261612</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-17</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>378.600367</td>\n",
       "      <td>1.934180</td>\n",
       "      <td>378.464862</td>\n",
       "      <td>1.946536</td>\n",
       "      <td>379.785872</td>\n",
       "      <td>2.865022</td>\n",
       "      <td>378.316909</td>\n",
       "      <td>1.983430</td>\n",
       "      <td>23.795211</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.535183</td>\n",
       "      <td>0.122651</td>\n",
       "      <td>-0.829524</td>\n",
       "      <td>0.134191</td>\n",
       "      <td>2.261805</td>\n",
       "      <td>1.345651</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-25</th>\n",
       "      <td>Ib</td>\n",
       "      <td>373.128684</td>\n",
       "      <td>1.096617</td>\n",
       "      <td>372.980000</td>\n",
       "      <td>1.047750</td>\n",
       "      <td>373.701830</td>\n",
       "      <td>1.259198</td>\n",
       "      <td>372.910000</td>\n",
       "      <td>1.004164</td>\n",
       "      <td>252.480327</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.095641</td>\n",
       "      <td>1.695622</td>\n",
       "      <td>-1.095864</td>\n",
       "      <td>2.090111</td>\n",
       "      <td>12.906779</td>\n",
       "      <td>7.022300</td>\n",
       "      <td>0.333523</td>\n",
       "      <td>0.239981</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               class  CO2168.mean  CO2168.std  CO2336.mean  CO2336.std  \\\n",
       "date                                                                     \n",
       "2000-01-01  nonevent   384.462000    2.284996   384.164462    2.135062   \n",
       "2000-01-20  nonevent   374.884615    0.415185   374.703333    0.385179   \n",
       "2000-01-23  nonevent   373.496585    0.189497   373.382593    0.172958   \n",
       "2000-02-17  nonevent   378.600367    1.934180   378.464862    1.946536   \n",
       "2000-03-25        Ib   373.128684    1.096617   372.980000    1.047750   \n",
       "\n",
       "            CO242.mean  CO242.std  CO2504.mean  CO2504.std   Glob.mean  ...  \\\n",
       "date                                                                    ...   \n",
       "2000-01-01  385.274688   2.211695   383.885077    1.955198   19.245511  ...   \n",
       "2000-01-20  375.621266   0.665720   374.674177    0.435480   31.107659  ...   \n",
       "2000-01-23  373.961481   0.235107   373.275062    0.165500   29.800885  ...   \n",
       "2000-02-17  379.785872   2.865022   378.316909    1.983430   23.795211  ...   \n",
       "2000-03-25  373.701830   1.259198   372.910000    1.004164  252.480327  ...   \n",
       "\n",
       "            T672.mean  T672.std   T84.mean   T84.std  UV_A.mean  UV_A.std  \\\n",
       "date                                                                        \n",
       "2000-01-01 -13.016471  0.525698 -12.422972  0.376324   1.635563  0.856948   \n",
       "2000-01-20  -8.997430  0.373927  -8.351043  0.575679   1.441109  0.741088   \n",
       "2000-01-23 -10.224472  0.965988  -9.651155  1.238891   2.677545  1.261612   \n",
       "2000-02-17  -1.535183  0.122651  -0.829524  0.134191   2.261805  1.345651   \n",
       "2000-03-25  -2.095641  1.695622  -1.095864  2.090111  12.906779  7.022300   \n",
       "\n",
       "            UV_B.mean  UV_B.std   CS.mean    CS.std  \n",
       "date                                                 \n",
       "2000-01-01   0.026438  0.014617  0.003374  0.000733  \n",
       "2000-01-20   0.022649  0.012479  0.001501  0.000572  \n",
       "2000-01-23   0.044759  0.023748  0.000764  0.000048  \n",
       "2000-02-17   0.030893  0.021903  0.002038  0.000751  \n",
       "2000-03-25   0.333523  0.239981  0.000662  0.000210  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npf = pd.read_csv('npf_train.csv')\n",
    "npf.index=npf['date']\n",
    "npf['class4'] = npf['class4'].astype('category')\n",
    "npf.drop(['id', 'partlybad', 'date'], axis=1, inplace=True)\n",
    "npf.rename(columns={'class4':'class'}, inplace=True)\n",
    "npf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4056f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2168.mean</th>\n",
       "      <th>CO2168.std</th>\n",
       "      <th>CO2336.mean</th>\n",
       "      <th>CO2336.std</th>\n",
       "      <th>CO242.mean</th>\n",
       "      <th>CO242.std</th>\n",
       "      <th>CO2504.mean</th>\n",
       "      <th>CO2504.std</th>\n",
       "      <th>Glob.mean</th>\n",
       "      <th>Glob.std</th>\n",
       "      <th>...</th>\n",
       "      <th>T672.std</th>\n",
       "      <th>T84.mean</th>\n",
       "      <th>T84.std</th>\n",
       "      <th>UV_A.mean</th>\n",
       "      <th>UV_A.std</th>\n",
       "      <th>UV_B.mean</th>\n",
       "      <th>UV_B.std</th>\n",
       "      <th>CS.mean</th>\n",
       "      <th>CS.std</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>384.462000</td>\n",
       "      <td>2.284996</td>\n",
       "      <td>384.164462</td>\n",
       "      <td>2.135062</td>\n",
       "      <td>385.274688</td>\n",
       "      <td>2.211695</td>\n",
       "      <td>383.885077</td>\n",
       "      <td>1.955198</td>\n",
       "      <td>19.245511</td>\n",
       "      <td>11.909549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>-12.422972</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>1.635563</td>\n",
       "      <td>0.856948</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>374.884615</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>374.703333</td>\n",
       "      <td>0.385179</td>\n",
       "      <td>375.621266</td>\n",
       "      <td>0.665720</td>\n",
       "      <td>374.674177</td>\n",
       "      <td>0.435480</td>\n",
       "      <td>31.107659</td>\n",
       "      <td>24.624718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373927</td>\n",
       "      <td>-8.351043</td>\n",
       "      <td>0.575679</td>\n",
       "      <td>1.441109</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>373.496585</td>\n",
       "      <td>0.189497</td>\n",
       "      <td>373.382593</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>373.961481</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>373.275062</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>29.800885</td>\n",
       "      <td>22.892316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>-9.651155</td>\n",
       "      <td>1.238891</td>\n",
       "      <td>2.677545</td>\n",
       "      <td>1.261612</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-17</th>\n",
       "      <td>378.600367</td>\n",
       "      <td>1.934180</td>\n",
       "      <td>378.464862</td>\n",
       "      <td>1.946536</td>\n",
       "      <td>379.785872</td>\n",
       "      <td>2.865022</td>\n",
       "      <td>378.316909</td>\n",
       "      <td>1.983430</td>\n",
       "      <td>23.795211</td>\n",
       "      <td>16.178905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122651</td>\n",
       "      <td>-0.829524</td>\n",
       "      <td>0.134191</td>\n",
       "      <td>2.261805</td>\n",
       "      <td>1.345651</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-25</th>\n",
       "      <td>373.128684</td>\n",
       "      <td>1.096617</td>\n",
       "      <td>372.980000</td>\n",
       "      <td>1.047750</td>\n",
       "      <td>373.701830</td>\n",
       "      <td>1.259198</td>\n",
       "      <td>372.910000</td>\n",
       "      <td>1.004164</td>\n",
       "      <td>252.480327</td>\n",
       "      <td>138.921953</td>\n",
       "      <td>...</td>\n",
       "      <td>1.695622</td>\n",
       "      <td>-1.095864</td>\n",
       "      <td>2.090111</td>\n",
       "      <td>12.906779</td>\n",
       "      <td>7.022300</td>\n",
       "      <td>0.333523</td>\n",
       "      <td>0.239981</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO2168.mean  CO2168.std  CO2336.mean  CO2336.std  CO242.mean  \\\n",
       "date                                                                       \n",
       "2000-01-01   384.462000    2.284996   384.164462    2.135062  385.274688   \n",
       "2000-01-20   374.884615    0.415185   374.703333    0.385179  375.621266   \n",
       "2000-01-23   373.496585    0.189497   373.382593    0.172958  373.961481   \n",
       "2000-02-17   378.600367    1.934180   378.464862    1.946536  379.785872   \n",
       "2000-03-25   373.128684    1.096617   372.980000    1.047750  373.701830   \n",
       "\n",
       "            CO242.std  CO2504.mean  CO2504.std   Glob.mean    Glob.std  ...  \\\n",
       "date                                                                    ...   \n",
       "2000-01-01   2.211695   383.885077    1.955198   19.245511   11.909549  ...   \n",
       "2000-01-20   0.665720   374.674177    0.435480   31.107659   24.624718  ...   \n",
       "2000-01-23   0.235107   373.275062    0.165500   29.800885   22.892316  ...   \n",
       "2000-02-17   2.865022   378.316909    1.983430   23.795211   16.178905  ...   \n",
       "2000-03-25   1.259198   372.910000    1.004164  252.480327  138.921953  ...   \n",
       "\n",
       "            T672.std   T84.mean   T84.std  UV_A.mean  UV_A.std  UV_B.mean  \\\n",
       "date                                                                        \n",
       "2000-01-01  0.525698 -12.422972  0.376324   1.635563  0.856948   0.026438   \n",
       "2000-01-20  0.373927  -8.351043  0.575679   1.441109  0.741088   0.022649   \n",
       "2000-01-23  0.965988  -9.651155  1.238891   2.677545  1.261612   0.044759   \n",
       "2000-02-17  0.122651  -0.829524  0.134191   2.261805  1.345651   0.030893   \n",
       "2000-03-25  1.695622  -1.095864  2.090111  12.906779  7.022300   0.333523   \n",
       "\n",
       "            UV_B.std   CS.mean    CS.std     class  \n",
       "date                                                \n",
       "2000-01-01  0.014617  0.003374  0.000733  nonevent  \n",
       "2000-01-20  0.012479  0.001501  0.000572  nonevent  \n",
       "2000-01-23  0.023748  0.000764  0.000048  nonevent  \n",
       "2000-02-17  0.021903  0.002038  0.000751  nonevent  \n",
       "2000-03-25  0.239981  0.000662  0.000210     event  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = npf.copy()\n",
    "new_class = np.array(['event']*len(binary), dtype='object')\n",
    "new_class[binary['class'] == 'nonevent'] = 'nonevent'\n",
    "binary['class2'] = new_class\n",
    "binary.drop('class', axis=1, inplace=True)\n",
    "binary.rename(columns={'class2':'class'}, inplace=True)\n",
    "binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6243da9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5347342995169082\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "multiclass_GNB = np.array(accuracies).mean()\n",
    "print(multiclass_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb87e5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7646859903381642\n"
     ]
    }
   ],
   "source": [
    "#Binary Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "binary_GNB = np.array(accuracies).mean()\n",
    "print(binary_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02b4246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5001932367149757\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = DummyClassifier(strategy='most_frequent')\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "multiclass_dummy = np.array(accuracies).mean()\n",
    "print(multiclass_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ccd966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4542512077294686\n"
     ]
    }
   ],
   "source": [
    "#Binary Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = DummyClassifier(strategy='most_frequent')\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "binary_dummy = np.array(accuracies).mean()\n",
    "print(binary_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51582d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighbors</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.598599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.591787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.591691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.587633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.587585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.587150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.583188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.582899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.580821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.578406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.576618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.576570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.571932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.565604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.565411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.561304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.493382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy\n",
       "Neighbors          \n",
       "14         0.598599\n",
       "9          0.591787\n",
       "13         0.591691\n",
       "5          0.587633\n",
       "17         0.587585\n",
       "6          0.587150\n",
       "7          0.583188\n",
       "11         0.582899\n",
       "4          0.581014\n",
       "8          0.580821\n",
       "10         0.578406\n",
       "15         0.576618\n",
       "18         0.576570\n",
       "12         0.571932\n",
       "16         0.565604\n",
       "19         0.565411\n",
       "3          0.565266\n",
       "20         0.561304\n",
       "1          0.539469\n",
       "2          0.493382"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiclass k-Nearest Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "max_neighbors = 20\n",
    "multiclass_kNN_acc = list()\n",
    "for i in range(max_neighbors):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=i+1)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    multiclass_kNN_acc.append(np.array(accuracies).mean())\n",
    "\n",
    "multiclass_kNN = pd.DataFrame()\n",
    "multiclass_kNN['Neighbors'] = range(1, max_neighbors+1)\n",
    "multiclass_kNN['Accuracy'] = multiclass_kNN_acc\n",
    "multiclass_kNN.index = multiclass_kNN['Neighbors']\n",
    "multiclass_kNN.drop('Neighbors', axis=1, inplace=True)\n",
    "multiclass_kNN = multiclass_kNN.sort_values(by='Accuracy', ascending=False)\n",
    "multiclass_kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10035a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighbors</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.801353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.799469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.790338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.788551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.788551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.786232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.786184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.785990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.783961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.783768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.779517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.777101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.777053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.772995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.772705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.768647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy\n",
       "Neighbors          \n",
       "8          0.801353\n",
       "9          0.799469\n",
       "3          0.792319\n",
       "14         0.790531\n",
       "19         0.790338\n",
       "13         0.788551\n",
       "18         0.788551\n",
       "15         0.786232\n",
       "17         0.786184\n",
       "12         0.785990\n",
       "11         0.783961\n",
       "16         0.783768\n",
       "20         0.779517\n",
       "5          0.777101\n",
       "10         0.777053\n",
       "7          0.772995\n",
       "1          0.772705\n",
       "4          0.768647\n",
       "6          0.766280\n",
       "2          0.731401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary k-Nearest Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "max_neighbors = 20\n",
    "binary_kNN_acc = list()\n",
    "for i in range(max_neighbors):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=i+1)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    binary_kNN_acc.append(np.array(accuracies).mean())\n",
    "\n",
    "binary_kNN = pd.DataFrame()\n",
    "binary_kNN['Neighbors'] = range(1, max_neighbors+1)\n",
    "binary_kNN['Accuracy'] = binary_kNN_acc\n",
    "binary_kNN.index = binary_kNN['Neighbors']\n",
    "binary_kNN.drop('Neighbors', axis=1, inplace=True)\n",
    "binary_kNN = binary_kNN.sort_values(by='Accuracy', ascending=False)\n",
    "binary_kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb635e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6753140096618357\n"
     ]
    }
   ],
   "source": [
    "#Binary Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "\n",
    "    model = Perceptron()\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "\n",
    "binary_perceptron = np.array(accuracies).mean()\n",
    "print(binary_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f1d74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5415942028985508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chained Binary Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "\n",
    "for train_index, test_index in kf.split(npf):\n",
    "    train = npf.iloc[train_index]\n",
    "    test = npf.iloc[test_index]\n",
    "    \n",
    "    EvNE_train = train.copy()\n",
    "    temp = np.array(['event']*len(EvNE_train), dtype='object')\n",
    "    temp[EvNE_train['class'] == 'nonevent'] = 'nonevent'\n",
    "    EvNE_train['class'] = temp\n",
    "    \n",
    "    IvII_train = train.copy()\n",
    "    IvII_train = IvII_train[IvII_train['class'] != 'nonevent']\n",
    "    temp = np.array(['Type I']*len(IvII_train), dtype='object')\n",
    "    temp[IvII_train['class'] == 'II'] = 'II'\n",
    "    IvII_train['class'] = temp\n",
    "    \n",
    "    AvB_train = train.copy()\n",
    "    AvB_train = AvB_train[(AvB_train['class'] == 'Ia') | (AvB_train['class'] == 'Ib')]\n",
    "    temp = np.array(['Ia']*len(AvB_train), dtype='object')\n",
    "    temp[AvB_train['class'] == 'Ib'] = 'Ib'\n",
    "    AvB_train['class'] = temp\n",
    "    \n",
    "    EvNE_model = Perceptron()\n",
    "    IvII_model = Perceptron()\n",
    "    AvB_model = Perceptron()\n",
    "    EvNE_model.fit(EvNE_train.drop('class', axis=1), EvNE_train['class'])\n",
    "    IvII_model.fit(IvII_train.drop('class', axis=1), IvII_train['class'])\n",
    "    AvB_model.fit(AvB_train.drop('class', axis=1), AvB_train['class'])\n",
    "    \n",
    "    predictions = list()\n",
    "    features_test = test.drop('class', axis=1)\n",
    "    target_test = test['class']\n",
    "    for date in test.index:\n",
    "        entry = features_test.loc[date]\n",
    "        pred = EvNE_model.predict([entry]) #Compare Event vs Nonevent\n",
    "        if pred == 'nonevent':\n",
    "            predictions.append(pred[0])\n",
    "        else:\n",
    "            pred = IvII_model.predict([entry]) #Compare Type I vs Type II\n",
    "            if pred == 'Type II':\n",
    "                predictions.append(pred[0])\n",
    "            else:\n",
    "                pred = AvB_model.predict([entry]) #Compare Type Ia vs Type Ib\n",
    "                predictions.append(pred[0])\n",
    "    predictions = np.array(predictions)            \n",
    "    correct_arr = (target_test == predictions).values\n",
    "    correct = len(predictions[correct_arr])\n",
    "    accuracies.append(correct/len(predictions))\n",
    "    \n",
    "chained_perceptron = np.array(accuracies).mean()\n",
    "chained_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e91f98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Split  Accuracy\n",
      "105    107  0.659324\n",
      "150    152  0.657246\n",
      "128    130  0.653140\n",
      "151    153  0.652850\n",
      "114    116  0.650821\n",
      "..     ...       ...\n",
      "426    428  0.499807\n",
      "454    456  0.499807\n",
      "419    421  0.499758\n",
      "433    435  0.499662\n",
      "418    420  0.499662\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Decision Tree\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "split_acc = list()\n",
    "for i in range(2, len(features)+1):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = DecisionTreeClassifier(min_samples_split=i)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    multiclass_tree = np.array(accuracies).mean()\n",
    "    split_acc.append(multiclass_tree)\n",
    "    \n",
    "tree_table = pd.DataFrame()\n",
    "tree_table['Split'] = list(range(2, len(features)+1))\n",
    "tree_table['Accuracy'] = split_acc\n",
    "tree_table.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "print(tree_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f49f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Split  Accuracy\n",
      "206    208  0.838309\n",
      "207    209  0.838261\n",
      "204    206  0.838261\n",
      "200    202  0.836184\n",
      "203    205  0.835797\n",
      "..     ...       ...\n",
      "418    420  0.430000\n",
      "435    437  0.425942\n",
      "448    450  0.425894\n",
      "425    427  0.425700\n",
      "453    455  0.410290\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Binary Decision Tree\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "split_acc = list()\n",
    "for i in range(2, len(features)+1):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = DecisionTreeClassifier(min_samples_split=i)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    binary_tree = np.array(accuracies).mean()\n",
    "    split_acc.append(binary_tree)\n",
    "    \n",
    "binary_tree_table = pd.DataFrame()\n",
    "binary_tree_table['Split'] = list(range(2, len(features)+1))\n",
    "binary_tree_table['Accuracy'] = split_acc\n",
    "binary_tree_table.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "print(binary_tree_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "864a1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=700, max_features='sqrt', min_samples_leaf=8,\n",
      "                       min_samples_split=6, n_estimators=150, n_jobs=-1)\n",
      "0.871207729468599\n"
     ]
    }
   ],
   "source": [
    "#Binary Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "df=pd.DataFrame(grid.cv_results_)\n",
    "df.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], ascending=(True, False, True), inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()\n",
    "\n",
    "print(df.loc[0, 'mean_test_score'])\n",
    "binary_random_forest_table = df.copy()\n",
    "binary_forest = binary_random_forest_table.loc[0, 'mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24c5bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_depth=950, min_samples_leaf=10,\n",
      "                       min_samples_split=3, n_estimators=550, n_jobs=-1)\n",
      "0.6615458937198068\n"
     ]
    }
   ],
   "source": [
    "#Binary Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "df=pd.DataFrame(grid.cv_results_)\n",
    "df.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], ascending=(True, False, True), inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()\n",
    "\n",
    "print(df.loc[0, 'mean_test_score'])\n",
    "multiclass_random_forest_table = df.copy()\n",
    "multiclass_forest = multiclass_random_forest_table.loc[0, 'mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b680ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.454251</td>\n",
       "      <td>0.500193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.871208</td>\n",
       "      <td>0.661546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.764686</td>\n",
       "      <td>0.534734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-Nearest Neighbors</th>\n",
       "      <td>0.772705</td>\n",
       "      <td>0.539469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.675314</td>\n",
       "      <td>0.541594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category                Binary  Multiclass\n",
       "Dummy                 0.454251    0.500193\n",
       "Random Forest         0.871208    0.661546\n",
       "Gaussian Naive Bayes  0.764686    0.534734\n",
       "k-Nearest Neighbors   0.772705    0.539469\n",
       "Perceptron            0.675314    0.541594"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_arr = [binary_dummy, binary_forest, binary_GNB, binary_kNN_acc[0], binary_perceptron, binary_tree]\n",
    "multiclass_arr = [multiclass_dummy, multiclass_forest, multiclass_GNB, multiclass_kNN_acc[0], chained_perceptron, \n",
    "                  multiclass_tree]\n",
    "names = ['Dummy', 'Random Forest', 'Gaussian Naive Bayes', 'k-Nearest Neighbors', 'Perceptron', 'Binary Tree']\n",
    "accuracy_table = pd.DataFrame(data=[binary_arr, multiclass_arr], columns=names)\n",
    "accuracy_table.index = ['Binary', 'Multiclass']\n",
    "accuracy_table.index.name = 'Category'\n",
    "accuracy_table = accuracy_table.transpose()\n",
    "accuracy_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c13650a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_depth=600, min_samples_split=10,\n",
      "                       n_estimators=900, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "forest_features = pd.read_csv('rf_binary.csv')\n",
    "forest_features.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "forest_features.sort_values(by='Overall', ascending=False, inplace=True)\n",
    "\n",
    "binary_n = 5 #number of features to take\n",
    "target = binary['class']\n",
    "binary_feature_names = forest_features.loc[:binary_n-1, 'names'].to_numpy() \n",
    "binary_features = binary[binary_feature_names]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "binary_random_forest_final_table=pd.DataFrame(grid.cv_results_)\n",
    "binary_random_forest_final_table.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], \n",
    "                                       ascending=(True, False, True), inplace=True)\n",
    "binary_random_forest_final_table.reset_index(drop=True, inplace=True)\n",
    "binary_random_forest_final_table.head()\n",
    "\n",
    "binary_random_forest_final = binary_random_forest_final_table.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2ec793b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_depth=900, max_features='sqrt',\n",
      "                       min_samples_leaf=7, min_samples_split=5,\n",
      "                       n_estimators=750, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "forest_features = pd.read_csv('rf_full.csv')\n",
    "forest_features.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "forest_features.sort_values(by='Overall', ascending=False, inplace=True)\n",
    "\n",
    "multiclass_n = 5 #number of features to take\n",
    "target = npf['class']\n",
    "multiclass_feature_names = forest_features.loc[:multiclass_n-1, 'names'].to_numpy() \n",
    "multiclass_features = npf[multiclass_feature_names]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "multiclass_random_forest_final_table=pd.DataFrame(grid.cv_results_)\n",
    "multiclass_random_forest_final_table.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], \n",
    "                                       ascending=(True, False, True), inplace=True)\n",
    "multiclass_random_forest_final_table.reset_index(drop=True, inplace=True)\n",
    "multiclass_random_forest_final_table.head()\n",
    "\n",
    "multiclass_random_forest_final = binary_random_forest_final_table.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "45e5776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_random_forest_final = binary_random_forest_final[['param_n_estimators', 'param_min_samples_split', \n",
    "                                                                 'param_min_samples_leaf', 'param_max_features', \n",
    "                                                                 'param_max_depth', 'param_bootstrap']]\n",
    "multiclass_random_forest_final = multiclass_random_forest_final[['param_n_estimators', 'param_min_samples_split', \n",
    "                                                                 'param_min_samples_leaf', 'param_max_features', \n",
    "                                                                 'param_max_depth', 'param_bootstrap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f468309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_n_estimators           900\n",
       "param_min_samples_split       10\n",
       "param_min_samples_leaf         1\n",
       "param_max_features          auto\n",
       "param_max_depth              600\n",
       "param_bootstrap            False\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_random_forest_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2b175ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Random Forest - Test Data\n",
    "\n",
    "test_data = pd.read_csv('npf_test_hidden.csv')\n",
    "multiclass_test_features = test_data[multiclass_feature_names]\n",
    "\n",
    "params = multiclass_random_forest_final\n",
    "multiclass_RCF = RandomForestClassifier(n_jobs=-1, n_estimators = params[0], min_samples_split=params[1], \n",
    "                                    min_samples_leaf=params[2], max_features=params[3], max_depth=params[4], \n",
    "                                    bootstrap=params[5])\n",
    "multiclass_RCF.fit(multiclass_features, npf['class'])\n",
    "multiclass_output = pd.DataFrame()\n",
    "multiclass_output['class4'] = multiclass_RCF.predict(multiclass_test_features)\n",
    "multiclass_output['nonevent'] = np.array(multiclass_RCF.predict_proba(multiclass_test_features))[:, 3]\n",
    "multiclass_output['p'] = np.ones(len(multiclass_output)) - np.array(multiclass_output['nonevent'])\n",
    "multiclass_output.drop('nonevent', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6cb25a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912663755458515"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict = multiclass_RCF.predict(npf[multiclass_feature_names])\n",
    "train_targets = npf['class']\n",
    "train_check = pd.DataFrame()\n",
    "train_check.index = npf.index\n",
    "train_check['Prediction'] = train_predict\n",
    "train_check['True'] = train_targets\n",
    "\n",
    "correct = 0\n",
    "for date in train_check.index:\n",
    "    prediction = train_check.loc[date, 'Prediction']\n",
    "    true = train_check.loc[date, 'True']\n",
    "    if (prediction == 'nonevent' and true == 'nonevent') or (prediction != 'nonevent' and true != 'nonevent'):\n",
    "        correct += 1\n",
    "        \n",
    "predicted_binary_accuracy = correct/len(npf)\n",
    "predicted_binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1602b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_check[train_check['Prediction'] == train_check['True']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "647e8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = list()\n",
    "features = npf[multiclass_feature_names]\n",
    "target = npf['class']\n",
    "\n",
    "binary_acc = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(n_jobs=-1, n_estimators = params[0], min_samples_split=params[1], min_samples_leaf=params[2],\n",
    "                                   max_features=params[3], max_depth=params[4], bootstrap=params[5])\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    train_predict = model.predict(features_test[multiclass_feature_names])\n",
    "    train_check = pd.DataFrame()\n",
    "    train_check['Prediction'] = train_predict\n",
    "    train_check['True'] = target_test.values\n",
    "\n",
    "    correct = 0\n",
    "    for date in train_check.index:\n",
    "        prediction = train_check.loc[date, 'Prediction']\n",
    "        true = train_check.loc[date, 'True']\n",
    "        if (prediction == 'nonevent' and true == 'nonevent') or (prediction != 'nonevent' and true != 'nonevent'):\n",
    "            correct += 1\n",
    "\n",
    "    binary_acc.append(correct/len(train_check))\n",
    "    \n",
    "binary_acc = np.array(binary_acc)\n",
    "predicted_binary_accuracy = binary_acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3bbbc1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8255072463768117"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "948bc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = [round(predicted_binary_accuracy, 2), 'class4'] + list(multiclass_output['class4'].values)\n",
    "output2 = ['', 'p'] + list(multiclass_output['p'].values)\n",
    "output = pd.DataFrame()\n",
    "output['1'] = output1\n",
    "output['2'] = output2\n",
    "output.to_csv('prediction.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970066a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
