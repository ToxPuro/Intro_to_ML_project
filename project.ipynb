{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a6f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8ca92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>CO2168.mean</th>\n",
       "      <th>CO2168.std</th>\n",
       "      <th>CO2336.mean</th>\n",
       "      <th>CO2336.std</th>\n",
       "      <th>CO242.mean</th>\n",
       "      <th>CO242.std</th>\n",
       "      <th>CO2504.mean</th>\n",
       "      <th>CO2504.std</th>\n",
       "      <th>Glob.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>T672.mean</th>\n",
       "      <th>T672.std</th>\n",
       "      <th>T84.mean</th>\n",
       "      <th>T84.std</th>\n",
       "      <th>UV_A.mean</th>\n",
       "      <th>UV_A.std</th>\n",
       "      <th>UV_B.mean</th>\n",
       "      <th>UV_B.std</th>\n",
       "      <th>CS.mean</th>\n",
       "      <th>CS.std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>384.462000</td>\n",
       "      <td>2.284996</td>\n",
       "      <td>384.164462</td>\n",
       "      <td>2.135062</td>\n",
       "      <td>385.274688</td>\n",
       "      <td>2.211695</td>\n",
       "      <td>383.885077</td>\n",
       "      <td>1.955198</td>\n",
       "      <td>19.245511</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.016471</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>-12.422972</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>1.635563</td>\n",
       "      <td>0.856948</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>374.884615</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>374.703333</td>\n",
       "      <td>0.385179</td>\n",
       "      <td>375.621266</td>\n",
       "      <td>0.665720</td>\n",
       "      <td>374.674177</td>\n",
       "      <td>0.435480</td>\n",
       "      <td>31.107659</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.997430</td>\n",
       "      <td>0.373927</td>\n",
       "      <td>-8.351043</td>\n",
       "      <td>0.575679</td>\n",
       "      <td>1.441109</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>373.496585</td>\n",
       "      <td>0.189497</td>\n",
       "      <td>373.382593</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>373.961481</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>373.275062</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>29.800885</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.224472</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>-9.651155</td>\n",
       "      <td>1.238891</td>\n",
       "      <td>2.677545</td>\n",
       "      <td>1.261612</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-17</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>378.600367</td>\n",
       "      <td>1.934180</td>\n",
       "      <td>378.464862</td>\n",
       "      <td>1.946536</td>\n",
       "      <td>379.785872</td>\n",
       "      <td>2.865022</td>\n",
       "      <td>378.316909</td>\n",
       "      <td>1.983430</td>\n",
       "      <td>23.795211</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.535183</td>\n",
       "      <td>0.122651</td>\n",
       "      <td>-0.829524</td>\n",
       "      <td>0.134191</td>\n",
       "      <td>2.261805</td>\n",
       "      <td>1.345651</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-25</th>\n",
       "      <td>Ib</td>\n",
       "      <td>373.128684</td>\n",
       "      <td>1.096617</td>\n",
       "      <td>372.980000</td>\n",
       "      <td>1.047750</td>\n",
       "      <td>373.701830</td>\n",
       "      <td>1.259198</td>\n",
       "      <td>372.910000</td>\n",
       "      <td>1.004164</td>\n",
       "      <td>252.480327</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.095641</td>\n",
       "      <td>1.695622</td>\n",
       "      <td>-1.095864</td>\n",
       "      <td>2.090111</td>\n",
       "      <td>12.906779</td>\n",
       "      <td>7.022300</td>\n",
       "      <td>0.333523</td>\n",
       "      <td>0.239981</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               class  CO2168.mean  CO2168.std  CO2336.mean  CO2336.std  \\\n",
       "date                                                                     \n",
       "2000-01-01  nonevent   384.462000    2.284996   384.164462    2.135062   \n",
       "2000-01-20  nonevent   374.884615    0.415185   374.703333    0.385179   \n",
       "2000-01-23  nonevent   373.496585    0.189497   373.382593    0.172958   \n",
       "2000-02-17  nonevent   378.600367    1.934180   378.464862    1.946536   \n",
       "2000-03-25        Ib   373.128684    1.096617   372.980000    1.047750   \n",
       "\n",
       "            CO242.mean  CO242.std  CO2504.mean  CO2504.std   Glob.mean  ...  \\\n",
       "date                                                                    ...   \n",
       "2000-01-01  385.274688   2.211695   383.885077    1.955198   19.245511  ...   \n",
       "2000-01-20  375.621266   0.665720   374.674177    0.435480   31.107659  ...   \n",
       "2000-01-23  373.961481   0.235107   373.275062    0.165500   29.800885  ...   \n",
       "2000-02-17  379.785872   2.865022   378.316909    1.983430   23.795211  ...   \n",
       "2000-03-25  373.701830   1.259198   372.910000    1.004164  252.480327  ...   \n",
       "\n",
       "            T672.mean  T672.std   T84.mean   T84.std  UV_A.mean  UV_A.std  \\\n",
       "date                                                                        \n",
       "2000-01-01 -13.016471  0.525698 -12.422972  0.376324   1.635563  0.856948   \n",
       "2000-01-20  -8.997430  0.373927  -8.351043  0.575679   1.441109  0.741088   \n",
       "2000-01-23 -10.224472  0.965988  -9.651155  1.238891   2.677545  1.261612   \n",
       "2000-02-17  -1.535183  0.122651  -0.829524  0.134191   2.261805  1.345651   \n",
       "2000-03-25  -2.095641  1.695622  -1.095864  2.090111  12.906779  7.022300   \n",
       "\n",
       "            UV_B.mean  UV_B.std   CS.mean    CS.std  \n",
       "date                                                 \n",
       "2000-01-01   0.026438  0.014617  0.003374  0.000733  \n",
       "2000-01-20   0.022649  0.012479  0.001501  0.000572  \n",
       "2000-01-23   0.044759  0.023748  0.000764  0.000048  \n",
       "2000-02-17   0.030893  0.021903  0.002038  0.000751  \n",
       "2000-03-25   0.333523  0.239981  0.000662  0.000210  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npf = pd.read_csv('npf_train.csv')\n",
    "npf.index=npf['date']\n",
    "npf['class4'] = npf['class4'].astype('category')\n",
    "npf.drop(['id', 'partlybad', 'date'], axis=1, inplace=True)\n",
    "npf.rename(columns={'class4':'class'}, inplace=True)\n",
    "npf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4056f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2168.mean</th>\n",
       "      <th>CO2168.std</th>\n",
       "      <th>CO2336.mean</th>\n",
       "      <th>CO2336.std</th>\n",
       "      <th>CO242.mean</th>\n",
       "      <th>CO242.std</th>\n",
       "      <th>CO2504.mean</th>\n",
       "      <th>CO2504.std</th>\n",
       "      <th>Glob.mean</th>\n",
       "      <th>Glob.std</th>\n",
       "      <th>...</th>\n",
       "      <th>T672.std</th>\n",
       "      <th>T84.mean</th>\n",
       "      <th>T84.std</th>\n",
       "      <th>UV_A.mean</th>\n",
       "      <th>UV_A.std</th>\n",
       "      <th>UV_B.mean</th>\n",
       "      <th>UV_B.std</th>\n",
       "      <th>CS.mean</th>\n",
       "      <th>CS.std</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>384.462000</td>\n",
       "      <td>2.284996</td>\n",
       "      <td>384.164462</td>\n",
       "      <td>2.135062</td>\n",
       "      <td>385.274688</td>\n",
       "      <td>2.211695</td>\n",
       "      <td>383.885077</td>\n",
       "      <td>1.955198</td>\n",
       "      <td>19.245511</td>\n",
       "      <td>11.909549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>-12.422972</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>1.635563</td>\n",
       "      <td>0.856948</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>374.884615</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>374.703333</td>\n",
       "      <td>0.385179</td>\n",
       "      <td>375.621266</td>\n",
       "      <td>0.665720</td>\n",
       "      <td>374.674177</td>\n",
       "      <td>0.435480</td>\n",
       "      <td>31.107659</td>\n",
       "      <td>24.624718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373927</td>\n",
       "      <td>-8.351043</td>\n",
       "      <td>0.575679</td>\n",
       "      <td>1.441109</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>373.496585</td>\n",
       "      <td>0.189497</td>\n",
       "      <td>373.382593</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>373.961481</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>373.275062</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>29.800885</td>\n",
       "      <td>22.892316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>-9.651155</td>\n",
       "      <td>1.238891</td>\n",
       "      <td>2.677545</td>\n",
       "      <td>1.261612</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-17</th>\n",
       "      <td>378.600367</td>\n",
       "      <td>1.934180</td>\n",
       "      <td>378.464862</td>\n",
       "      <td>1.946536</td>\n",
       "      <td>379.785872</td>\n",
       "      <td>2.865022</td>\n",
       "      <td>378.316909</td>\n",
       "      <td>1.983430</td>\n",
       "      <td>23.795211</td>\n",
       "      <td>16.178905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122651</td>\n",
       "      <td>-0.829524</td>\n",
       "      <td>0.134191</td>\n",
       "      <td>2.261805</td>\n",
       "      <td>1.345651</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>nonevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-25</th>\n",
       "      <td>373.128684</td>\n",
       "      <td>1.096617</td>\n",
       "      <td>372.980000</td>\n",
       "      <td>1.047750</td>\n",
       "      <td>373.701830</td>\n",
       "      <td>1.259198</td>\n",
       "      <td>372.910000</td>\n",
       "      <td>1.004164</td>\n",
       "      <td>252.480327</td>\n",
       "      <td>138.921953</td>\n",
       "      <td>...</td>\n",
       "      <td>1.695622</td>\n",
       "      <td>-1.095864</td>\n",
       "      <td>2.090111</td>\n",
       "      <td>12.906779</td>\n",
       "      <td>7.022300</td>\n",
       "      <td>0.333523</td>\n",
       "      <td>0.239981</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO2168.mean  CO2168.std  CO2336.mean  CO2336.std  CO242.mean  \\\n",
       "date                                                                       \n",
       "2000-01-01   384.462000    2.284996   384.164462    2.135062  385.274688   \n",
       "2000-01-20   374.884615    0.415185   374.703333    0.385179  375.621266   \n",
       "2000-01-23   373.496585    0.189497   373.382593    0.172958  373.961481   \n",
       "2000-02-17   378.600367    1.934180   378.464862    1.946536  379.785872   \n",
       "2000-03-25   373.128684    1.096617   372.980000    1.047750  373.701830   \n",
       "\n",
       "            CO242.std  CO2504.mean  CO2504.std   Glob.mean    Glob.std  ...  \\\n",
       "date                                                                    ...   \n",
       "2000-01-01   2.211695   383.885077    1.955198   19.245511   11.909549  ...   \n",
       "2000-01-20   0.665720   374.674177    0.435480   31.107659   24.624718  ...   \n",
       "2000-01-23   0.235107   373.275062    0.165500   29.800885   22.892316  ...   \n",
       "2000-02-17   2.865022   378.316909    1.983430   23.795211   16.178905  ...   \n",
       "2000-03-25   1.259198   372.910000    1.004164  252.480327  138.921953  ...   \n",
       "\n",
       "            T672.std   T84.mean   T84.std  UV_A.mean  UV_A.std  UV_B.mean  \\\n",
       "date                                                                        \n",
       "2000-01-01  0.525698 -12.422972  0.376324   1.635563  0.856948   0.026438   \n",
       "2000-01-20  0.373927  -8.351043  0.575679   1.441109  0.741088   0.022649   \n",
       "2000-01-23  0.965988  -9.651155  1.238891   2.677545  1.261612   0.044759   \n",
       "2000-02-17  0.122651  -0.829524  0.134191   2.261805  1.345651   0.030893   \n",
       "2000-03-25  1.695622  -1.095864  2.090111  12.906779  7.022300   0.333523   \n",
       "\n",
       "            UV_B.std   CS.mean    CS.std     class  \n",
       "date                                                \n",
       "2000-01-01  0.014617  0.003374  0.000733  nonevent  \n",
       "2000-01-20  0.012479  0.001501  0.000572  nonevent  \n",
       "2000-01-23  0.023748  0.000764  0.000048  nonevent  \n",
       "2000-02-17  0.021903  0.002038  0.000751  nonevent  \n",
       "2000-03-25  0.239981  0.000662  0.000210     event  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = npf.copy()\n",
    "new_class = np.array(['event']*len(binary), dtype='object')\n",
    "new_class[binary['class'] == 'nonevent'] = 'nonevent'\n",
    "binary['class2'] = new_class\n",
    "binary.drop('class', axis=1, inplace=True)\n",
    "binary.rename(columns={'class2':'class'}, inplace=True)\n",
    "binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1290fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208212560386473\n"
     ]
    }
   ],
   "source": [
    "#Binary SVM\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "binary_SVM = np.array(accuracies).mean()\n",
    "print(binary_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f7de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6008212560386473\n"
     ]
    }
   ],
   "source": [
    "#Multiclass SVM\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "multiclass_SVM = np.array(accuracies).mean()\n",
    "print(multiclass_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb87e5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7814975845410628\n"
     ]
    }
   ],
   "source": [
    "#Binary Gaussian Naive Bayes\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "binary_GNB = np.array(accuracies).mean()\n",
    "print(binary_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6243da9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5416908212560385\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Gaussian Naive Bayes\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "multiclass_GNB = np.array(accuracies).mean()\n",
    "print(multiclass_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02b4246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500048309178744\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Dummy Classifier\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = DummyClassifier(strategy='most_frequent')\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "multiclass_dummy = np.array(accuracies).mean()\n",
    "print(multiclass_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ccd966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4585990338164251\n"
     ]
    }
   ],
   "source": [
    "#Binary Dummy Classifier\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "    \n",
    "    model = DummyClassifier(strategy='most_frequent')\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "binary_dummy = np.array(accuracies).mean()\n",
    "print(binary_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51582d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighbors</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.604541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.598309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.593816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.589227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.587295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.585169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.584976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.584928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.582899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.580821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.580676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.578744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.578406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.578261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.576570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.571932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.556908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy\n",
       "Neighbors          \n",
       "14         0.604541\n",
       "6          0.598309\n",
       "13         0.593816\n",
       "5          0.589662\n",
       "7          0.589227\n",
       "12         0.587295\n",
       "8          0.585169\n",
       "4          0.584976\n",
       "19         0.584928\n",
       "20         0.582899\n",
       "10         0.580821\n",
       "17         0.580676\n",
       "15         0.578744\n",
       "16         0.578406\n",
       "11         0.578261\n",
       "18         0.576570\n",
       "9          0.571932\n",
       "3          0.556908\n",
       "1          0.537246\n",
       "2          0.484734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiclass k-Nearest Neighbors Classifier\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "max_neighbors = 20\n",
    "multiclass_kNN_acc = list()\n",
    "for i in range(max_neighbors):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=i+1)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    multiclass_kNN_acc.append(np.array(accuracies).mean())\n",
    "\n",
    "multiclass_kNN = pd.DataFrame()\n",
    "multiclass_kNN['Neighbors'] = range(1, max_neighbors+1)\n",
    "multiclass_kNN['Accuracy'] = multiclass_kNN_acc\n",
    "multiclass_kNN.index = multiclass_kNN['Neighbors']\n",
    "multiclass_kNN.drop('Neighbors', axis=1, inplace=True)\n",
    "multiclass_kNN = multiclass_kNN.sort_values(by='Accuracy', ascending=False)\n",
    "multiclass_kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c073742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "sns.scatterplot(data=multiclass_kNN, x='Neighbors', y='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10035a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighbors</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.792512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.790580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.790483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.790290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.788164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.788068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.785894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.785845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.781787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.781594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.781401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.779614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.775362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.775266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.770386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.755362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.740290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy\n",
       "Neighbors          \n",
       "9          0.792512\n",
       "11         0.790580\n",
       "8          0.790531\n",
       "10         0.790483\n",
       "17         0.790290\n",
       "5          0.788164\n",
       "14         0.788068\n",
       "20         0.785894\n",
       "12         0.785845\n",
       "16         0.781787\n",
       "19         0.781594\n",
       "13         0.781401\n",
       "15         0.779614\n",
       "3          0.779372\n",
       "7          0.775362\n",
       "18         0.775266\n",
       "6          0.770386\n",
       "4          0.764203\n",
       "1          0.755362\n",
       "2          0.740290"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary k-Nearest Neighbors Classifier\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "max_neighbors = 20\n",
    "binary_kNN_acc = list()\n",
    "for i in range(max_neighbors):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=i+1)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    binary_kNN_acc.append(np.array(accuracies).mean())\n",
    "\n",
    "binary_kNN = pd.DataFrame()\n",
    "binary_kNN['Neighbors'] = range(1, max_neighbors+1)\n",
    "binary_kNN['Accuracy'] = binary_kNN_acc\n",
    "binary_kNN.index = binary_kNN['Neighbors']\n",
    "binary_kNN.drop('Neighbors', axis=1, inplace=True)\n",
    "binary_kNN = binary_kNN.sort_values(by='Accuracy', ascending=False)\n",
    "binary_kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb635e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666280193236715\n"
     ]
    }
   ],
   "source": [
    "#Binary Perceptron\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "\n",
    "    model = Perceptron()\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracies.append(model.score(features_test, target_test))\n",
    "\n",
    "binary_perceptron = np.array(accuracies).mean()\n",
    "print(binary_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f1d74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4740579710144927"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chained Binary Perceptron\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "accuracies = list()\n",
    "\n",
    "for train_index, test_index in kf.split(npf):\n",
    "    train = npf.iloc[train_index]\n",
    "    test = npf.iloc[test_index]\n",
    "    \n",
    "    EvNE_train = train.copy()\n",
    "    temp = np.array(['event']*len(EvNE_train), dtype='object')\n",
    "    temp[EvNE_train['class'] == 'nonevent'] = 'nonevent'\n",
    "    EvNE_train['class'] = temp\n",
    "    \n",
    "    IvII_train = train.copy()\n",
    "    IvII_train = IvII_train[IvII_train['class'] != 'nonevent']\n",
    "    temp = np.array(['Type I']*len(IvII_train), dtype='object')\n",
    "    temp[IvII_train['class'] == 'II'] = 'II'\n",
    "    IvII_train['class'] = temp\n",
    "    \n",
    "    AvB_train = train.copy()\n",
    "    AvB_train = AvB_train[(AvB_train['class'] == 'Ia') | (AvB_train['class'] == 'Ib')]\n",
    "    temp = np.array(['Ia']*len(AvB_train), dtype='object')\n",
    "    temp[AvB_train['class'] == 'Ib'] = 'Ib'\n",
    "    AvB_train['class'] = temp\n",
    "    \n",
    "    EvNE_model = Perceptron()\n",
    "    IvII_model = Perceptron()\n",
    "    AvB_model = Perceptron()\n",
    "    EvNE_model.fit(EvNE_train.drop('class', axis=1), EvNE_train['class'])\n",
    "    IvII_model.fit(IvII_train.drop('class', axis=1), IvII_train['class'])\n",
    "    AvB_model.fit(AvB_train.drop('class', axis=1), AvB_train['class'])\n",
    "    \n",
    "    predictions = list()\n",
    "    features_test = test.drop('class', axis=1)\n",
    "    target_test = test['class']\n",
    "    for date in test.index:\n",
    "        entry = features_test.loc[date]\n",
    "        pred = EvNE_model.predict([entry]) #Compare Event vs Nonevent\n",
    "        if pred == 'nonevent':\n",
    "            predictions.append(pred[0])\n",
    "        else:\n",
    "            pred = IvII_model.predict([entry]) #Compare Type I vs Type II\n",
    "            if pred == 'Type II':\n",
    "                predictions.append(pred[0])\n",
    "            else:\n",
    "                pred = AvB_model.predict([entry]) #Compare Type Ia vs Type Ib\n",
    "                predictions.append(pred[0])\n",
    "    predictions = np.array(predictions)            \n",
    "    correct_arr = (target_test == predictions).values\n",
    "    correct = len(predictions[correct_arr])\n",
    "    accuracies.append(correct/len(predictions))\n",
    "    \n",
    "chained_perceptron = np.array(accuracies).mean()\n",
    "chained_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e91f98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Split  Accuracy\n",
      "106    108  0.655362\n",
      "151    153  0.652802\n",
      "132    134  0.650386\n",
      "129    131  0.648454\n",
      "145    147  0.646425\n",
      "..     ...       ...\n",
      "433    435  0.499710\n",
      "453    455  0.499710\n",
      "451    453  0.499662\n",
      "429    431  0.499662\n",
      "428    430  0.499614\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Decision Tree\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "split_acc = list()\n",
    "for i in range(2, len(features)+1):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = DecisionTreeClassifier(min_samples_split=i)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    multiclass_tree = np.array(accuracies).mean()\n",
    "    split_acc.append(multiclass_tree)\n",
    "    \n",
    "tree_table = pd.DataFrame()\n",
    "tree_table['Split'] = list(range(2, len(features)+1))\n",
    "tree_table['Accuracy'] = split_acc\n",
    "tree_table.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "print(tree_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f49f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Split  Accuracy\n",
      "202    204  0.840773\n",
      "203    205  0.838502\n",
      "208    210  0.838406\n",
      "206    208  0.838213\n",
      "199    201  0.836280\n",
      "..     ...       ...\n",
      "436    438  0.419275\n",
      "418    420  0.419227\n",
      "453    455  0.414734\n",
      "446    448  0.412705\n",
      "419    421  0.410628\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Binary Decision Tree\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "split_acc = list()\n",
    "for i in range(2, len(features)+1):\n",
    "    accuracies = list()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = DecisionTreeClassifier(min_samples_split=i)\n",
    "        model.fit(features_train, target_train)\n",
    "        accuracies.append(model.score(features_test, target_test))\n",
    "    binary_tree = np.array(accuracies).mean()\n",
    "    split_acc.append(binary_tree)\n",
    "    \n",
    "binary_tree_table = pd.DataFrame()\n",
    "binary_tree_table['Split'] = list(range(2, len(features)+1))\n",
    "binary_tree_table['Accuracy'] = split_acc\n",
    "binary_tree_table.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "print(binary_tree_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864a1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=600, max_features='sqrt', min_samples_leaf=10,\n",
      "                       min_samples_split=6, n_estimators=750, n_jobs=-1)\n",
      "0.8690338164251209\n"
     ]
    }
   ],
   "source": [
    "#Binary Random Forest\n",
    "\n",
    "RFC = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "features = binary.drop('class', axis=1)\n",
    "target = binary['class']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "df=pd.DataFrame(grid.cv_results_)\n",
    "df.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], ascending=(True, False, True), inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()\n",
    "\n",
    "print(df.loc[0, 'mean_test_score'])\n",
    "binary_random_forest_table = df.copy()\n",
    "binary_forest = binary_random_forest_table.loc[0, 'mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24c5bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6593719806763285\n"
     ]
    }
   ],
   "source": [
    "#Multiclass Random Forest\n",
    "\n",
    "RFC = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "features = npf.drop('class', axis=1)\n",
    "target = npf['class']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "multiclass_random_forest_table=pd.DataFrame(grid.cv_results_)\n",
    "multiclass_random_forest_table.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], ascending=(True, False, True), inplace=True)\n",
    "multiclass_random_forest_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(multiclass_random_forest_table.loc[0, 'mean_test_score'])\n",
    "multiclass_forest = multiclass_random_forest_table.loc[0, 'mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b680ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.458599</td>\n",
       "      <td>0.500048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.869034</td>\n",
       "      <td>0.659372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.781498</td>\n",
       "      <td>0.541691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-Nearest Neighbors</th>\n",
       "      <td>0.755362</td>\n",
       "      <td>0.537246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.666280</td>\n",
       "      <td>0.474058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.840773</td>\n",
       "      <td>0.655362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category                Binary  Multiclass\n",
       "Dummy                 0.458599    0.500048\n",
       "Random Forest         0.869034    0.659372\n",
       "Gaussian Naive Bayes  0.781498    0.541691\n",
       "k-Nearest Neighbors   0.755362    0.537246\n",
       "Perceptron            0.666280    0.474058\n",
       "Decision Tree         0.840773    0.655362"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy Comparison Table\n",
    "\n",
    "binary_arr = [binary_dummy, binary_forest, binary_GNB, binary_kNN_acc[0], binary_perceptron, \n",
    "              binary_tree_table['Accuracy'].iloc[0]]\n",
    "multiclass_arr = [multiclass_dummy, multiclass_forest, multiclass_GNB, multiclass_kNN_acc[0], chained_perceptron, \n",
    "                  tree_table['Accuracy'].iloc[0]]\n",
    "names = ['Dummy', 'Random Forest', 'Gaussian Naive Bayes', 'k-Nearest Neighbors', 'Perceptron', 'Decision Tree']\n",
    "accuracy_table = pd.DataFrame(data=[binary_arr, multiclass_arr], columns=names)\n",
    "accuracy_table.index = ['Binary', 'Multiclass']\n",
    "accuracy_table.index.name = 'Category'\n",
    "accuracy_table = accuracy_table.transpose()\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db72576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Count  Accuracy\n",
      "16     17  0.625135\n",
      "7       8  0.623754\n",
      "14     15  0.621623\n",
      "2       3  0.621425\n",
      "18     19  0.620778\n",
      "24     25  0.619609\n",
      "17     18  0.619063\n",
      "22     23  0.617836\n",
      "8       9  0.617536\n",
      "23     24  0.616807\n",
      "13     14  0.616667\n",
      "15     16  0.615932\n",
      "19     20  0.615295\n",
      "10     11  0.614237\n",
      "6       7  0.613995\n",
      "3       4  0.612527\n",
      "9      10  0.611164\n",
      "20     21  0.609440\n",
      "21     22  0.609222\n",
      "5       6  0.606570\n",
      "12     13  0.605203\n",
      "4       5  0.604908\n",
      "11     12  0.603488\n",
      "1       2  0.546507\n",
      "0       1  0.417063\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVi0lEQVR4nO3df/Ac9X3f8efrK4l8bUnkBwjhYrAgg0uDZ0zsr7EdGw8Og0ehdokbG0Onk2Q6tYodTB0mrZn+4SSd6UzrNNTFOGGgpZPM2GaIHRwlgzGuEwfacVxJRDYITC0Y2agyCBTXgJxvEHzf/ePuS798tV/p7vju3XH3fMxovrd7u3fv1d7taz+f3dtNVSFJ0nIzoy5AkjSeDAhJUiMDQpLUyICQJDUyICRJjdaOuoDVdPLJJ9eWLVtGXYYkvWzs2rXryara1PTcRAXEli1b2Llz56jLkKSXjSTfXek5u5gkSY0MCElSIwNCktTIgJAkNTIgJEmNJuosJkntWVgo9h06zONPzbP5xFm2nLSemZmMuiy1yICQdFwLC8Wdex7jmtt2M39kgdl1M1x32XlsPfdUQ2KC2cWk1i0sFI888Qxff/hJHnniGRYWvMT8y82+Q4dfCAeA+SMLXHPbbvYdOjziytQmWxBqlXuek+Hxp+ZfCIdF80cWOPj0PGdt2jCiqtQ2WxBDMM170O55tm8Yn6/NJ84yu+7Fm4vZdTOcsnF2Vd9nmr8r48gWRMumfQ/aPc92DevzteWk9Vx32XlHvc+Wk9av2ntM+3dlEG2fOGBAtGylPehzrr5gKjaQi3ueS0OijT3PaTWsz9fMTNh67qmcc/UFHHx6nlM2Hn9j1O/Ga9q/K/0aRqDaxdSyY+1BT4PFPc/F7ole9jztZujdMD9fMzPhrE0beMtZJ3PWpg3HDYc79zzGJdffwxU3f4NLrr+HO/c8dsx1OWnflbY/x8PovrUF0bJp34Pud8/Tbob+9rzH9fM1SGtgXJdlEIN8jvttcQ2j+9YWRMsG2YOeNP3seU77Qe1+97wH/Xy1vXc7SGtgkr4r/X6OB2lxDePEAVsQLRuk73aaTftB7X73vAc9NtB2K22Q1sCg35Vx/IV3v5/jQVpcwzhxwIAYgsU96EnYwLX9ZRxmN8MkbFig/8/XMA4GD7rx6ndZxrVLst/P8aDrve2dTwNiTI3jxmsYX8Zh7BXB5GxYBjGUvushtZzH9cynfj/Hg673tnc+DYgxNK4br2F8Gd2wtB+Qw2qlDaPlPK5dkv1+joe1Y9QvA2IMjevGa1hfxkE2LON4BsgghhGQ47oxGsQ4n/nUz+d4XI9VGhBjaFw3XuP6ZRykxTWuywLt73mP68ZoEIOE3SDdt8Po8h3HY5UGxBga143XuO55jusZIONsHDdGgxjG72zGtct3GFI1Ob9SnZubq507d466jJdsnD+Qi3tS47Tn+fWHn+SKm79x1Phbt72Zt5x18orzjeOyqF2PPPEMl1x/z1E7X3ccY2dikHleTpLsqqq5pudsQYyhYXUBDNJsHsc9z3E9A0TjZ5Du23Ht8h0GA2JMtX2gdpxbKf0a5+6icTxdeZoNsjMxrl2+w2AX04Tod4M/ac3mcewumqQQnhQegzjasbqYDIgJ0e8Gf9B++2nWb2tg0kJ4UgyyMzGOOyCrxWMQU6DfftJpbjYPYpC9yGnuux5ng3TfTuvxKq/mOiH6vbLjJF05cxgGucrssG7TKbWl1YBIsjXJQ0n2Jrl2hWkuTLI7yZ4kf9nPvPr/+t3gL54pdcfVF3Drtjdzx9UXTEyfahum/fLVmk6tdTElWQN8GrgY2A/sSLK9qh5YMs1PAL8HbK2q7yU5pdd59WKDnBo7rc3mQQzz8tXSuGizBXE+sLeqHqmqZ4FbgUuXTfNPgD+uqu8BVNXBPubVMv3cmEf9GbQ14DrRy1mbB6lPAx5dMrwfePOyaV4LrEvyNWAj8J+r6g97nBeAJNuAbQBnnHHGqhQuLWdrQNOozYBo+uYsP6d2LfBG4CLgFcDXk/xVj/N2RlbdBNwEndNcB65WOg675DRt2gyI/cDpS4ZfDRxomObJqjoMHE5yN/D6HueVJLWozWMQO4Czk5yZ5ATgcmD7smn+BLggydokr6TTjfRgj/NKklrUWguiqp5LchXwZWANcEtV7UlyZff5G6vqwSR3At8CFoD/UlX3AzTN21atkqSjeakNSZpix7rUhr+kliQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY1aDYgkW5M8lGRvkmsbnr8wyQ+T7O7++/iS5/Ylua87fmebdUqSjra2rRdOsgb4NHAxsB/YkWR7VT2wbNJ7qurdK7zMO6vqybZqlCStrM0WxPnA3qp6pKqeBW4FLm3x/SRJq6jNgDgNeHTJ8P7uuOXemuSbSb6U5Nwl4wu4K8muJNtarFOS1KC1LiYgDeNq2fC9wGuq6pkklwBfBM7uPve2qjqQ5BTgK0m+XVV3H/UmnfDYBnDGGWesWvErWVgo9h06zONPzbP5xFm2nLSemZmmRZWkl7c2WxD7gdOXDL8aOLB0gqp6qqqe6T6+A1iX5OTu8IHu34PA7XS6rI5SVTdV1VxVzW3atGn1l2KJhYXizj2Pccn193DFzd/gkuvv4c49j7GwsDz3JOnlr82A2AGcneTMJCcAlwPbl06Q5NQk6T4+v1vPoSTrk2zsjl8PvAu4v8Vae7Lv0GGuuW0380cWAJg/ssA1t+1m36HDI65MklZfa11MVfVckquALwNrgFuqak+SK7vP3wi8D/hQkueAvwUur6pKshm4vZsda4HPVtWdbdXaq8efmn8hHBbNH1ng4NPznLVpw4iqkqR2tHkMYrHb6I5l425c8vgG4IaG+R4BXt9mbYPYfOIss+tmXhQSs+tmOGXj7AirkqR2+EvqPmw5aT3XXXYes+s6/22z62a47rLz2HLS+hFXJkmrr9UWxKSZmQlbzz2Vc66+gINPz3PKRs9ikjS5jhsQSd4N3FFVC8ebdhrMzISzNm3wmIOkiddLF9PlwHeSfCLJP2i7IEnSeDhuQFTVPwV+FngY+G9Jvp5k2+JpqJKkydTTQeqqegr4Ap3rKb0KeC9wb5KPtFibJGmEjhsQSd6T5Hbgz4F1wPlV9Qt0TkP9jZbrkySNSC9nMb0f+E/Lr4NUVT9K8s/aKUuSNGq9BMRvAt9fHEjyCmBzVe2rqq+2VpkkaaR6OQbxR8DSU1yf746TJE2wXgJibfeGPwB0H5/QXkmSpHHQS0A8keQfLQ4kuRTwNqCSNOF6OQZxJfCZJDfQuQnQo8Avt1qVJGnkjhsQVfUw8JYkG4BU1dPtlyVJGrWeLtaX5B8C5wKz3Xs0UFX/tsW6JEkj1ssP5W4EPgB8hE4X0/uB17RclyRpxHo5SP1zVfXLwA+q6reBt/Lie01LkiZQLwEx3/37oyR/DzgCnNleSZKkcdDLMYg/TfITwO8A9wIF3NxmUZKk0TtmQCSZAb5aVf8X+EKSPwNmq+qHwyhOkjQ6x+xi6t5F7neXDP+d4SBJ06GXYxB3JfmlLJ7fKkmaCr0cg7gGWA88l2SezqmuVVUntlqZJGmkevkltbcWlaQpdNyASPKOpvHLbyAkSZosvXQx/aslj2eB84FdwM+3UpEkaSz00sX0nqXDSU4HPtFaRZKksdDLWUzL7Qdet9qFSJLGSy/HID5F59fT0AmU84BvtliTJGkM9HIMYueSx88Bn6uq/9lSPZKkMdFLQHwemK+q5wGSrEnyyqr6UbulSZJGqZdjEF8FXrFk+BXAf2+nHEnSuOglIGar6pnFge7jV7ZXkiRpHPQSEIeTvGFxIMkbgb9tryRJ0jjo5RjER4E/SnKgO/wqOrcglSRNsF5+KLcjyTnA36dzob5vV9WR1iuTJI3UcbuYkvwasL6q7q+q+4ANST7cfmmSpFHq5RjEB7t3lAOgqn4AfLC1iiRJY6GXgJhZerOgJGuAE9orSZI0DnoJiC8DtyW5KMnPA58DvtTLiyfZmuShJHuTXNvw/IVJfphkd/ffx3udV5LUrl7OYvoYsA34EJ2D1H9N50ymY+q2ND4NXEznAn87kmyvqgeWTXpPVb17wHklSS05bguiqhaAvwIeAeaAi4AHe3jt84G9VfVIVT0L3Apc2mNdL2VeSdIqWDEgkrw2yceTPAjcADwKUFXvrKobenjt0xbn6drfHbfcW5N8M8mXkpzb57wk2ZZkZ5KdTzzxRA9lSZJ6cawWxLfptBbeU1Vvr6pPAc/38dppGFfLhu8FXlNVrwc+BXyxj3k7I6tuqqq5qprbtGlTH+VJko7lWAHxS8BjwF8kuTnJRTRvuFeyHzh9yfCrgQNLJ6iqpxav81RVdwDrkpzcy7ySpHatGBBVdXtVfQA4B/ga8OvA5iS/n+RdPbz2DuDsJGcmOQG4HNi+dIIkpy6eQpvk/G49h3qZV5LUrl4utXEY+AzwmSQ/BbwfuBa46zjzPZfkKjqnya4BbqmqPUmu7D5/I/A+4ENJnqNzAcDLq6qAxnkHXUhJUv/S2R5Phrm5udq5c+fxJ5QkAZBkV1XNNT3Xyw/lJElTyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTIgJAkNTIgJEmNDAhJUiMDQpLUyICQJDVqNSCSbE3yUJK9Sa49xnRvSvJ8kvctGbcvyX1JdifZ2WadkqSjrW3rhZOsAT4NXAzsB3Yk2V5VDzRM9x+ALze8zDur6sm2apQkrazNFsT5wN6qeqSqngVuBS5tmO4jwBeAgy3WIknqU5sBcRrw6JLh/d1xL0hyGvBe4MaG+Qu4K8muJNtaq1KS1Ki1LiYgDeNq2fAngY9V1fPJUZO/raoOJDkF+EqSb1fV3Ue9SSc8tgGcccYZL71qSRLQbgtiP3D6kuFXAweWTTMH3JpkH/A+4PeS/CJAVR3o/j0I3E6ny+ooVXVTVc1V1dymTZtWdQEkaZq1GRA7gLOTnJnkBOByYPvSCarqzKraUlVbgM8DH66qLyZZn2QjQJL1wLuA+1usVZK0TGtdTFX1XJKr6JydtAa4par2JLmy+3zTcYdFm4Hbu91Oa4HPVtWdbdUqSTpaqpYfFnj5mpubq507/cmEJPUqya6qmmt6zl9SS5IaGRCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBoQkqZEBIUlqZEBIkhoZEJKkRgaEJKmRASFJamRASJIaGRCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBoQkqZEBIUlqZEBIkhoZEJKkRgaEJKnR2lEXMGoLC8W+Q4d5/Kl5Np84y5aT1jMzk1GXJUkjN9UBsbBQ3LnnMa65bTfzRxaYXTfDdZedx9ZzTzUkJE29qe5i2nfo8AvhADB/ZIFrbtvNvkOHR1yZJI3eVAfE40/NvxAOi+aPLHDw6fkRVSRJ42OqA2LzibPMrnvxf8HsuhlO2Tg7oookaXxMdUBsOWk911123gshsXgMYstJ60dcmSSN3lQfpJ6ZCVvPPZVzrr6Ag0/Pc8pGz2KSpEVTHRDQCYmzNm3grE0bRl2KJI2Vqe5ikiStzICQJDUyICRJjQwISVIjA0KS1ChVNeoaVk2SJ4DvAicDT464nFGa5uV32afXNC//S1n211TVpqYnJiogFiXZWVVzo65jVKZ5+V326Vx2mO7lb2vZ7WKSJDUyICRJjSY1IG4adQEjNs3L77JPr2le/laWfSKPQUiSXrpJbUFIkl4iA0KS1GjiAiLJ1iQPJdmb5NpR1zNMSfYluS/J7iQ7R11P25LckuRgkvuXjPupJF9J8p3u358cZY1tWWHZfyvJ/+mu/91JLhlljW1JcnqSv0jyYJI9Sf5ld/y0rPuVln/V1/9EHYNIsgb438DFwH5gB3BFVT0w0sKGJMk+YK6qpuLHQkneATwD/GFVva477hPA31TVv+/uIPxkVX1slHW2YYVl/y3gmar6j6OsrW1JXgW8qqruTbIR2AX8IvCrTMe6X2n5L2OV1/+ktSDOB/ZW1SNV9SxwK3DpiGtSS6rqbuBvlo2+FPiD7uM/oPPFmTgrLPtUqKrvV9W93cdPAw8CpzE9636l5V91kxYQpwGPLhneT0v/cWOqgLuS7EqybdTFjMjmqvo+dL5IwCkjrmfYrkryrW4X1ER2sSyVZAvws8A3mMJ1v2z5YZXX/6QFRNO9QienD+343lZVbwB+Afi1bjeEpsfvAz8NnAd8H/jdkVbTsiQbgC8AH62qp0Zdz7A1LP+qr/9JC4j9wOlLhl8NHBhRLUNXVQe6fw8Ct9Ppcps2j3f7aBf7ag+OuJ6hqarHq+r5qloAbmaC13+SdXQ2jp+pqj/ujp6add+0/G2s/0kLiB3A2UnOTHICcDmwfcQ1DUWS9d0DViRZD7wLuP/Yc02k7cCvdB//CvAnI6xlqBY3jl3vZULXf5IA/xV4sKquW/LUVKz7lZa/jfU/UWcxAXRP7foksAa4par+3WgrGo4kZ9FpNQCsBT476cue5HPAhXQudfw48JvAF4HbgDOA7wHvr6qJO5i7wrJfSKd7oYB9wL9Y7JOfJEneDtwD3AcsdEf/Gzr98NOw7lda/itY5fU/cQEhSVodk9bFJElaJQaEJKmRASFJamRASJIaGRCSpEYGhNSnJKcmuTXJw0keSHJHkteu4utfmOTnVuv1pEEZEFIfuj9Suh34WlX9dFX9DJ1z0Dev4ttcCBgQGjkDQurPO4EjVXXj4oiq2g38jyS/k+T+7j05PgAvtAb+bHHaJDck+dXu431JfjvJvd15zulefO1K4Ne71/S/YIjLJr3I2lEXIL3MvI7O9feX+8d0fsX6ejq/bt6R5O4eXu/JqnpDkg8Dv1FV/zzJjUzBfR00/mxBSKvj7cDnuhdLexz4S+BNPcy3eKG5XcCWlmqTBmJASP3ZA7yxYXzTpeYBnuPF37PZZc//Xffv89ii15gxIKT+/DnwY0k+uDgiyZuAHwAfSLImySbgHcD/Ar4L/EySH0vy48BFPbzH08DG1S9d6o97LFIfqqqSvBf4ZPe+x/N0rpz5UWAD8E06V9P811X1GECS24BvAd8B/rqHt/lT4PNJLgU+UlX3rPZySL3waq6SpEZ2MUmSGhkQkqRGBoQkqZEBIUlqZEBIkhoZEJKkRgaEJKnR/wOsIR3Wjpt2egAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Multiclass Random Forest Feature Number Selection\n",
    "\n",
    "forest_features = pd.read_csv('rf_full.csv')\n",
    "forest_features.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "forest_features.sort_values(by='Overall', ascending=False, inplace=True)\n",
    "rkf = RepeatedKFold(n_splits=10, n_repeats=10)\n",
    "\n",
    "feature_count = list(range(1, len(forest_features)+1))\n",
    "accuracy = list()\n",
    "for i in feature_count:\n",
    "    feature_names = forest_features.loc[:i-1, 'names']\n",
    "    features = npf[feature_names]\n",
    "    target = npf['class']\n",
    "    fold_accuracy = list()\n",
    "    for train_index, test_index in rkf.split(features):\n",
    "        features_train = features.iloc[train_index]\n",
    "        features_test = features.iloc[test_index]\n",
    "        target_train = target.iloc[train_index]\n",
    "        target_test = target.iloc[test_index]\n",
    "\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(features_train, target_train)\n",
    "        fold_accuracy.append(model.score(features_test, target_test))\n",
    "    accuracy.append(np.array(fold_accuracy).mean())\n",
    "\n",
    "count_table = pd.DataFrame()\n",
    "count_table['Count'] = feature_count\n",
    "count_table['Accuracy'] = accuracy\n",
    "\n",
    "count_table.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "print(count_table)\n",
    "plt.clf()\n",
    "sns.scatterplot(data=count_table, x='Count', y='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec793b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiclass Random Forest with Reduced Features\n",
    "\n",
    "multiclass_n = 4 #number of features to take\n",
    "target = npf['class']\n",
    "multiclass_feature_names = forest_features.loc[:multiclass_n-1, 'names'].to_numpy() \n",
    "multiclass_features = npf[multiclass_feature_names]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':list(range(50, 1001, 50)),                       \n",
    "    'max_features': ['auto','sqrt'], \n",
    "    'max_depth': list(range(50, 1001, 50))+[None],\n",
    "    'min_samples_split': list(range(2, 11)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'bootstrap': [True,False]\n",
    "}\n",
    "\n",
    "RFC = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "grid = RandomizedSearchCV(RFC, cv=10, param_distributions=param_grid, n_iter=100)\n",
    "grid.fit(features, target)\n",
    "\n",
    "multiclass_random_forest_final_table=pd.DataFrame(grid.cv_results_)\n",
    "multiclass_random_forest_final_table.sort_values(by=['rank_test_score', 'mean_test_score', 'std_test_score'], \n",
    "                                       ascending=(True, False, True), inplace=True)\n",
    "multiclass_random_forest_final_table.reset_index(drop=True, inplace=True)\n",
    "multiclass_random_forest_final_table.head()\n",
    "\n",
    "multiclass_random_forest_final = multiclass_random_forest_final_table.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751324a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.123372</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.191654</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>900</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.643961</td>\n",
       "      <td>0.054699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077032</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.016853</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>450</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.643865</td>\n",
       "      <td>0.056081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412932</td>\n",
       "      <td>0.015979</td>\n",
       "      <td>0.058584</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>700</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.641787</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904717</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.185139</td>\n",
       "      <td>0.031263</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>700</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.639614</td>\n",
       "      <td>0.054737</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.177220</td>\n",
       "      <td>0.045278</td>\n",
       "      <td>0.189612</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.639565</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.150529</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.606812</td>\n",
       "      <td>0.043185</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.900399</td>\n",
       "      <td>0.108925</td>\n",
       "      <td>0.169569</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>800</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.604686</td>\n",
       "      <td>0.034417</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.185821</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>350</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.604686</td>\n",
       "      <td>0.051931</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.184459</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>0.030043</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.602609</td>\n",
       "      <td>0.043665</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.410390</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.074873</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>450</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600338</td>\n",
       "      <td>0.040042</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.123372      0.044156         0.191654        0.010914   \n",
       "1        0.077032      0.003695         0.016853        0.001754   \n",
       "2        0.412932      0.015979         0.058584        0.002329   \n",
       "3        0.904717      0.029375         0.185139        0.031263   \n",
       "4        1.177220      0.045278         0.189612        0.006637   \n",
       "..            ...           ...              ...             ...   \n",
       "95       0.150529      0.009159         0.025828        0.002090   \n",
       "96       0.900399      0.108925         0.169569        0.024098   \n",
       "97       0.185821      0.007462         0.030481        0.002051   \n",
       "98       0.184459      0.012409         0.030043        0.002383   \n",
       "99       0.410390      0.027597         0.074873        0.006278   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                 900                       9                      2   \n",
       "1                  50                       8                      1   \n",
       "2                 250                       4                      2   \n",
       "3                 750                       2                      3   \n",
       "4                 900                       3                      3   \n",
       "..                ...                     ...                    ...   \n",
       "95                100                       5                      4   \n",
       "96                800                       8                     10   \n",
       "97                100                       3                      9   \n",
       "98                100                       2                      4   \n",
       "99                400                       5                      9   \n",
       "\n",
       "   param_max_features param_max_depth param_bootstrap  ... split3_test_score  \\\n",
       "0                sqrt             400           False  ...          0.673913   \n",
       "1                auto             450           False  ...          0.652174   \n",
       "2                auto             700           False  ...          0.630435   \n",
       "3                sqrt             700           False  ...          0.630435   \n",
       "4                auto            1000           False  ...          0.630435   \n",
       "..                ...             ...             ...  ...               ...   \n",
       "95               sqrt             150            True  ...          0.608696   \n",
       "96               sqrt             150            True  ...          0.608696   \n",
       "97               sqrt             350            True  ...          0.608696   \n",
       "98               sqrt            1000            True  ...          0.565217   \n",
       "99               sqrt             450            True  ...          0.608696   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.565217           0.695652           0.695652   \n",
       "1            0.565217           0.652174           0.739130   \n",
       "2            0.565217           0.717391           0.695652   \n",
       "3            0.543478           0.673913           0.673913   \n",
       "4            0.565217           0.652174           0.695652   \n",
       "..                ...                ...                ...   \n",
       "95           0.608696           0.630435           0.652174   \n",
       "96           0.565217           0.652174           0.630435   \n",
       "97           0.565217           0.673913           0.652174   \n",
       "98           0.608696           0.630435           0.608696   \n",
       "99           0.565217           0.673913           0.586957   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.673913           0.688889           0.533333         0.643961   \n",
       "1            0.673913           0.644444           0.533333         0.643865   \n",
       "2            0.630435           0.666667           0.555556         0.641787   \n",
       "3            0.673913           0.688889           0.533333         0.639614   \n",
       "4            0.673913           0.666667           0.533333         0.639565   \n",
       "..                ...                ...                ...              ...   \n",
       "95           0.652174           0.622222           0.511111         0.606812   \n",
       "96           0.630435           0.622222           0.533333         0.604686   \n",
       "97           0.630435           0.622222           0.533333         0.604686   \n",
       "98           0.673913           0.666667           0.533333         0.602609   \n",
       "99           0.652174           0.622222           0.533333         0.600338   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.054699                1  \n",
       "1         0.056081                2  \n",
       "2         0.059501                3  \n",
       "3         0.054737                4  \n",
       "4         0.049556                5  \n",
       "..             ...              ...  \n",
       "95        0.043185               96  \n",
       "96        0.034417               97  \n",
       "97        0.051931               97  \n",
       "98        0.043665               99  \n",
       "99        0.040042              100  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_random_forest_final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b175ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiclass Random Forest - Test Data\n",
    "\n",
    "test_data = pd.read_csv('npf_test_hidden.csv')\n",
    "multiclass_test_features = test_data[multiclass_feature_names]\n",
    "\n",
    "params = multiclass_random_forest_final[['param_n_estimators', 'param_min_samples_split', 'param_min_samples_leaf', \n",
    "                                         'param_max_features', 'param_max_depth', 'param_bootstrap']]\n",
    "\n",
    "multiclass_RCF = RandomForestClassifier(n_jobs=-1, n_estimators = params[0], min_samples_split=params[1], \n",
    "                                    min_samples_leaf=params[2], max_features=params[3], max_depth=params[4], \n",
    "                                    bootstrap=params[5])\n",
    "multiclass_RCF.fit(multiclass_features, npf['class'])\n",
    "multiclass_output = pd.DataFrame()\n",
    "multiclass_output['class4'] = multiclass_RCF.predict(multiclass_test_features)\n",
    "multiclass_output['nonevent'] = np.array(multiclass_RCF.predict_proba(multiclass_test_features))[:, 3]\n",
    "multiclass_output['p'] = np.ones(len(multiclass_output)) - np.array(multiclass_output['nonevent'])\n",
    "multiclass_output.drop('nonevent', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "647e8828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282125603864734"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute (Expected) Binary Accuracy of Multiclass Random Forest Classifier\n",
    "\n",
    "accuracies = list()\n",
    "features = npf[multiclass_feature_names]\n",
    "target = npf['class']\n",
    "\n",
    "binary_acc = list()\n",
    "rkf = RepeatedKFold(n_splits=10, n_repeats=10)\n",
    "for train_index, test_index in rkf.split(features):\n",
    "    features_train = features.iloc[train_index]\n",
    "    features_test = features.iloc[test_index]\n",
    "    target_train = target.iloc[train_index]\n",
    "    target_test = target.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(n_jobs=-1, n_estimators = params[0], min_samples_split=params[1], min_samples_leaf=params[2],\n",
    "                                   max_features=params[3], max_depth=params[4], bootstrap=params[5])\n",
    "\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    train_predict = model.predict(features_test[multiclass_feature_names])\n",
    "    train_check = pd.DataFrame()\n",
    "    train_check['Prediction'] = train_predict\n",
    "    train_check['True'] = target_test.values\n",
    "\n",
    "    correct = 0\n",
    "    for date in train_check.index:\n",
    "        prediction = train_check.loc[date, 'Prediction']\n",
    "        true = train_check.loc[date, 'True']\n",
    "        if (prediction == 'nonevent' and true == 'nonevent') or (prediction != 'nonevent' and true != 'nonevent'):\n",
    "            correct += 1\n",
    "\n",
    "    binary_acc.append(correct/len(train_check))\n",
    "    \n",
    "binary_acc = np.array(binary_acc)\n",
    "predicted_binary_accuracy = binary_acc.mean()\n",
    "predicted_binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "948bc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = [round(predicted_binary_accuracy, 2), 'class4'] + list(multiclass_output['class4'].values)\n",
    "output2 = ['', 'p'] + list(multiclass_output['p'].values)\n",
    "output = pd.DataFrame()\n",
    "output['1'] = output1\n",
    "output['2'] = output2\n",
    "output.to_csv('prediction.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970066a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
